node('jupiter-16G-1'){            // Running on x86 runner containing latest vector qemu, latest vector gcc and all the necessary libraries
    stage('Cleanup'){
        cleanWs()               // Cleaning previous CI build in workspace
    }
    stage('Install dependencies'){
        sh'''
            #!/bin/bash

            set -x

            sudo apt update
            sudo apt install -y cmake build-essential git curl libcurl4-openssl-dev
        '''
    }
    stage('checkout repo'){
        retry(5){               // Retry if the cloning fails due to some reason
            checkout scm        // Clone the repo on Runner
        }
    }
    stage('Compiling llama.cpp'){
        sh'''#!/bin/bash
            
            set -x

            mkdir -p .compiler_override
                
            # Create symlinks in this temp directory
            ln -sf /usr/bin/gcc-14 .compiler_override/gcc
            ln -sf /usr/bin/g++-14 .compiler_override/g++
            
            export CC="/usr/bin/gcc-14"
            export CXX="/usr/bin/g++-14"

            # Prepend the temp directory to PATH for this script's execution
            export PATH="$PWD/.compiler_override:$PATH"

            gcc --version
            g++ --version

            cmake -B build
            cmake --build build --config Release -j8 --target llama-cli llama-quantize
        '''
    }
    stage('Running llama.cpp'){
        sh'''#!/bin/bash
            
            set -x
            GGUF_WEIGHT="/home/jenkins_user/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf"  # Path to the GGUF model file
           ./build/bin/llama-cli -m {GGUF_WEIGHT} -p "Hi, how are you?" -n 10
        '''
    }
}
